{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data into Neptune DB\n",
    "\n",
    "After completing the data generation, you are now ready to import the CSV graph data into Neptune Database.\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Upload the data to S3\n",
    "2. Import the data into Neptune DB using the Neptune Loader API\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, ensure you have:\n",
    "1. A Neptune DB instance\n",
    "2. An S3 bucket in the same region as your Neptune DB\n",
    "3. An IAM role for Neptune to access S3\n",
    "4. An S3 VPC endpoint configured\n",
    "\n",
    "All this infrastructure is created by the CDK project attached with this example, and saved in the file `cdk_outputs.json`, allowing you to simply run through this notebook\n",
    "\n",
    "For infrastructure setup instructions, see the README under `neptune-database-graphstorm-online-inference/neptune-db-cdk/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "import boto3\n",
    "import requests\n",
    "import urllib3\n",
    "from botocore.auth import SigV4Auth\n",
    "from botocore.awsrequest import AWSRequest\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util import Retry\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, force=True)\n",
    "logging.getLogger(\"boto3\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"botocore\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"urllib3\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"s3transfer\").setLevel(logging.WARNING)\n",
    "\n",
    "# Disable SSL warnings since we're using localhost\n",
    "urllib3.disable_warnings()\n",
    "config_obj = %graph_notebook_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve resources created by CDK\n",
    "with open(\n",
    "    f\"{os.environ['HOME']}/SageMaker/cdk_outputs.json\", \"r\", encoding=\"utf-8\"\n",
    ") as f:\n",
    "    cdk_outputs = json.load(f)\n",
    "\n",
    "ACCOUNT_ID = cdk_outputs[\"ACCOUNT_ID\"]\n",
    "AWS_REGION = cdk_outputs[\"AWS_REGION\"]\n",
    "S3_BUCKET = cdk_outputs[\"NDB_STACK_S3_BUCKET\"]\n",
    "S3_GRAPH_PREFIX = f\"s3://{S3_BUCKET}/neptune-input/ieee-cis-with-text-embeddings\"\n",
    "\n",
    "GRAPH_NAME = \"ieee-cis-ndb\"\n",
    "\n",
    "# Neptune configuration\n",
    "NEPTUNE_ENDPOINT = config_obj.host\n",
    "NEPTUNE_PORT = 8182\n",
    "NEPTUNE_HOST = config_obj.host\n",
    "IAM_ROLE_ARN = config_obj.load_from_s3_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload processed data to S3 to start Neptune import\n",
    "\n",
    "To import the graph into Neptune you will first need to upload to an S3 location that's accessible by the Neptune instance.\n",
    "\n",
    "During stack creation we created a new S3 bucket and set up the necessary permissions to allow this notebook instance and the Neptune instance\n",
    "to read and write from it. So to start the import process you will first upload the processed graph data to this S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 sync ./ieee-cis-fraud-detection/ {S3_GRAPH_PREFIX}/edges/ --exclude \"*\" --include \"Edge*.csv\"\n",
    "!aws s3 sync ./ieee-cis-fraud-detection/ {S3_GRAPH_PREFIX}/vertices/ --exclude \"*\" --include \"Vertex*.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data into Neptune DB\n",
    "\n",
    "Now that we have our data in S3 in the correct format, let's use the Neptune Loader API to import it.\n",
    "\n",
    "To speed up the process you will import the graph in two separate steps, first importing all the vertices, then performing an optimized load of the edges only.\n",
    "\n",
    "As a rule of thumb to speed up data imports you should:\n",
    "\n",
    "* Minimize import size. If your data has columns you don't plan to use in your Neptune graph, it's better to remove them.\n",
    "* Launch separate import jobs for vertex and edges, with the vertex job first, then for edges provide the `'edgeOnlyLoad': 'TRUE'` parameter to the load request.\n",
    "* Use `'parallelism': 'OVERSUBSCRIBE'` to allocate entire cluster to loading if not doing other work on the cluster during import.\n",
    "* Use single files per vertex/edge type (instead of num_chunks=16). NDB uses intra-file parallelism, so many small files are bad, while NA does the opposite\n",
    "* Use larger writer instances.\n",
    "\n",
    "See the [Neptune documentation](https://docs.aws.amazon.com/neptune/latest/userguide/bulk-load-optimize.html) for more advice on optimizing imports.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next notebook we set up functions to load data, with separate handling for edge-only loads, and functions to monitor the load process.\n",
    "\n",
    "The data loading step should take around 4 minutes to complete on a `r8g.xlarge` instance and is asynchronous so you can proceed to the model training\n",
    "notebook and come back later to verify the job has finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_session():\n",
    "    \"\"\"Create a requests session with retry configuration and AWS auth.\"\"\"\n",
    "    retry_strategy = Retry(\n",
    "        total=3, backoff_factor=1, status_forcelist=[500, 502, 503, 504]\n",
    "    )\n",
    "    session = requests.Session()\n",
    "    adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "    session.mount(\"https://\", adapter)\n",
    "    session.verify = False  # Disable SSL verification for localhost\n",
    "\n",
    "    return session\n",
    "\n",
    "\n",
    "def load_data_to_neptune(\n",
    "    source_prefix,\n",
    "    format=\"csv\",\n",
    "    is_edge_only=False,\n",
    "):\n",
    "    \"\"\"Load data into Neptune DB using the Neptune Loader API.\n",
    "\n",
    "    Args:\n",
    "        source_prefix: S3 prefix containing the data files\n",
    "        format: Data format (csv for Gremlin)\n",
    "        is_edge_only: Whether the load operation is for edges only\n",
    "    \"\"\"\n",
    "    session = create_session()\n",
    "    boto3_session = boto3.Session()\n",
    "    credentials = boto3_session.get_credentials()\n",
    "    region = boto3_session.region_name\n",
    "\n",
    "    # Prepare the loader request\n",
    "    loader_endpoint = f\"https://{NEPTUNE_ENDPOINT}:{NEPTUNE_PORT}/loader\"\n",
    "\n",
    "    payload = {\n",
    "        \"source\": source_prefix,\n",
    "        \"format\": format,\n",
    "        \"iamRoleArn\": IAM_ROLE_ARN,\n",
    "        \"region\": AWS_REGION,\n",
    "        \"failOnError\": \"TRUE\",\n",
    "        \"parallelism\": \"OVERSUBSCRIBE\",\n",
    "        \"queueRequest\": \"TRUE\",\n",
    "        \"updateSingleCardinalityProperties\": \"FALSE\",\n",
    "        \"edgeOnlyLoad\": str(is_edge_only).upper(),\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Create request for signing\n",
    "        request = AWSRequest(\n",
    "            method=\"POST\",\n",
    "            url=loader_endpoint,\n",
    "            data=json.dumps(payload),\n",
    "            headers={\"Content-Type\": \"application/json\", \"Host\": NEPTUNE_HOST},\n",
    "        )\n",
    "        SigV4Auth(credentials, \"neptune-db\", region).add_auth(request)\n",
    "        headers = dict(request.headers)\n",
    "\n",
    "        # Start the load job\n",
    "        response = session.post(\n",
    "            loader_endpoint, headers=headers, json=payload, timeout=30\n",
    "        )\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"Failed to start load job: {response.text}\")\n",
    "\n",
    "        load_id = response.json()[\"payload\"][\"loadId\"]\n",
    "        print(f\"Started load job with ID: {load_id}\")\n",
    "        return load_id\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error connecting to Neptune: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def check_load_status(load_id, include_errors=False, page=1, errors_per_page=10):\n",
    "    \"\"\"Check the status of a Neptune load job.\n",
    "\n",
    "    Args:\n",
    "        load_id: The ID of the load job to check\n",
    "        include_errors: Whether to include the list of errors (default: False)\n",
    "        page: The error page number when include_errors is True (default: 1)\n",
    "        errors_per_page: Number of errors per page when include_errors is True (default: 10)\n",
    "\n",
    "    Returns:\n",
    "        dict: The load status response from Neptune\n",
    "    \"\"\"\n",
    "    session = create_session()\n",
    "    boto3_session = boto3.Session()\n",
    "    credentials = boto3_session.get_credentials()\n",
    "    region = boto3_session.region_name\n",
    "\n",
    "    # Construct base URL with load_id\n",
    "    status_endpoint = f\"https://{NEPTUNE_ENDPOINT}:{NEPTUNE_PORT}/loader/{load_id}\"\n",
    "\n",
    "    # Add query parameters\n",
    "    params = []\n",
    "    if include_errors:\n",
    "        params.append(\"errors=TRUE\")\n",
    "        params.append(f\"page={page}\")\n",
    "        params.append(f\"errorsPerPage={errors_per_page}\")\n",
    "\n",
    "    # Append parameters to URL if any exist\n",
    "    if params:\n",
    "        status_endpoint += \"?\" + \"&\".join(params)\n",
    "\n",
    "    try:\n",
    "        # Create request for signing\n",
    "        request = AWSRequest(\n",
    "            method=\"GET\", url=status_endpoint, headers={\"Host\": NEPTUNE_HOST}\n",
    "        )\n",
    "        SigV4Auth(credentials, \"neptune-db\", region).add_auth(request)\n",
    "        headers = dict(request.headers)\n",
    "\n",
    "        response = session.get(status_endpoint, headers=headers, timeout=30)\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"Failed to get load status: {response.text}\")\n",
    "\n",
    "        status = response.json()\n",
    "        print(f\"Load Status: {json.dumps(status, indent=2)}\")\n",
    "        return status\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error checking load status: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def wait_for_load_completion(load_id, max_attempts=60, sleep_time=30):\n",
    "    \"\"\"Wait for a Neptune load job to complete.\n",
    "\n",
    "    Args:\n",
    "        load_id: The ID of the load job to wait for\n",
    "        max_attempts: Maximum number of status checks (default: 60)\n",
    "        sleep_time: Time to sleep between checks in seconds (default: 30)\n",
    "\n",
    "    Returns:\n",
    "        dict: The final status of the load job\n",
    "\n",
    "    Raises:\n",
    "        Exception: If the load job fails or times out\n",
    "    \"\"\"\n",
    "    print(f\"Waiting for load job {load_id} to complete...\")\n",
    "    attempts = 0\n",
    "\n",
    "    while attempts < max_attempts:\n",
    "        try:\n",
    "            status = check_load_status(load_id)\n",
    "            overall_status = (\n",
    "                status.get(\"payload\", {}).get(\"overallStatus\", {}).get(\"status\")\n",
    "            )\n",
    "\n",
    "            if overall_status == \"LOAD_COMPLETED\":\n",
    "                print(\"Load job completed successfully!\")\n",
    "                return status\n",
    "            elif overall_status in [\"LOAD_FAILED\", \"LOAD_CANCELLED\"]:\n",
    "                error_logs = status.get(\"payload\", {}).get(\"errors\", [])\n",
    "                raise Exception(\n",
    "                    f\"Load job failed with status {overall_status}. Errors: {error_logs}\"\n",
    "                )\n",
    "\n",
    "            attempts += 1\n",
    "            print(\n",
    "                f\"Current status: {overall_status}. Waiting {sleep_time} seconds before next check...\"\n",
    "            )\n",
    "            time.sleep(sleep_time)\n",
    "        except Exception as e:\n",
    "            print(f\"Error during status check: {str(e)}\")\n",
    "            attempts += 1\n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "    raise Exception(f\"Load job timed out after {max_attempts} attempts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, start the vertex loading process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_load_id = load_data_to_neptune(f\"{S3_GRAPH_PREFIX}/vertices/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, schedule the edge loading job that will be queued after the vertex job, because we use `\"queueRequest\": \"TRUE\"` in our request inside `load_data_to_neptune`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_load_id = load_data_to_neptune(f\"{S3_GRAPH_PREFIX}/edges/\", is_edge_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, you can wait for the load process to finish and get the output, which should take around 4 minutes on a `db.r8g.4xlarge`, or less if you used a larger instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_status = wait_for_load_completion(vertex_load_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_status = wait_for_load_completion(edges_load_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "While Neptune is loading the data, you can proceed to the next notebook, `2-Model-Training.ipynb`, to run model training with GraphStorm locally. In that notebook you will train a GraphStorm model and produce the necessary files to deploy a GraphStorm SageMaker endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
