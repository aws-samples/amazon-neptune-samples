{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72783ba9",
   "metadata": {},
   "source": [
    "## Investigate GNN embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d5be75",
   "metadata": {},
   "source": [
    "After importing the new graph into Neptune Analytics you can further explore the graph, using the GNN's predictions as a way to focus on potentially fraudulent transaction. \n",
    "\n",
    "Neptune Analytics has created a vector index for the embeddings on which you can run similarity and topk queries. You can also make use of the GraphStorm predictions included for each transaction node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b49ecf6",
   "metadata": {},
   "source": [
    "## Upload this notebook to your graph notebook instance\n",
    "\n",
    "In note book `1-SageMaker-Setup` you created a SageMaker AI notebook instance, that comes pre-configured as a [Graph Notebook](https://github.com/aws/graph-notebook). This will allow you to run OpenCypher queries against your graph directly from the notebook.\n",
    "\n",
    "<!-- TODO: Remove when we include the notebook download in the LCC -->\n",
    "To use this notebook you will need to upload it to that instance (a [Graph Notebook](https://docs.aws.amazon.com/neptune-analytics/latest/userguide/notebooks.html) that can access your graph endpoint and submit queries) and run the cells there using the default `python3` kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ca5806",
   "metadata": {},
   "source": [
    "### Risk Score Validation using Known Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bf538d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Fraud detection systems often rely on risk scores, but their effectiveness needs\n",
    "constant validation. In this section, you will analyze how well the prediction model\n",
    "performs against known fraud cases. By segmenting transactions into risk bands\n",
    "(Very Low to Very High), you can see the actual fraud rates in each band and\n",
    "validate the model's ability to identify suspicious transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ef3701",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%oc\n",
    "// Detailed risk band analysis\n",
    "MATCH (t:Transaction)\n",
    "WITH CASE\n",
    "    WHEN t.pred < 0.2 THEN \"Very Low Risk (0-0.2)\"\n",
    "    WHEN t.pred < 0.4 THEN \"Low Risk (0.2-0.4)\"\n",
    "    WHEN t.pred < 0.6 THEN \"Medium Risk (0.4-0.6)\"\n",
    "    WHEN t.pred < 0.8 THEN \"High Risk (0.6-0.8)\"\n",
    "    ELSE \"Very High Risk (0.8-1.0)\"\n",
    "END as risk_category,\n",
    "    t.pred as risk_score,\n",
    "    t.isFraud as is_fraud\n",
    "WITH risk_category,\n",
    "     count(*) as total_cases,\n",
    "     sum(is_fraud) as confirmed_fraud,\n",
    "     sum(risk_score) as risk_sum\n",
    "WHERE total_cases > 5\n",
    "RETURN\n",
    "    risk_category,\n",
    "    total_cases,\n",
    "    confirmed_fraud,\n",
    "    round(1000.0 * confirmed_fraud / total_cases) / 1000.0 as fraud_rate,\n",
    "    round(1000.0 * risk_sum / total_cases) / 1000.0 as avg_risk_score\n",
    "ORDER BY avg_risk_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a524af0-cc5a-4196-bff3-8cfd6bc2b7b7",
   "metadata": {},
   "source": [
    "From the above analysis you can see that the model has good alignment with the actual fraud rates. You can now proceed with a deeper investigation of the fraud patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7284d011",
   "metadata": {},
   "source": [
    "### Community Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1de5ad",
   "metadata": {},
   "source": [
    "One advantage of graph-based analysis is the ability to find natural clusters in the transaction network. Using Neptune's community detection capabilities, you can identify groups of transactions that form natural communities based on the way the connect to other nodes in the graph. These communities might represent normal business patterns, but they could also reveal coordinated fraudulent activities. The GNN predictions can help you differentiate between benign and potentially harmful groups.\n",
    "\n",
    "This step transforms the transaction network from a collection of individual events into meaningful groups for fraud analysis using the [Louvain](https://docs.aws.amazon.com/neptune-analytics/latest/userguide/louvain.html) community detection algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc9ea4c",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%oc\n",
    "\n",
    "CALL neptune.algo.louvain.mutate(\n",
    "  {\n",
    "    writeProperty: \"louvainCommunity\",\n",
    "    maxLevels: 3,\n",
    "    maxIterations: 10\n",
    "  }\n",
    ")\n",
    "YIELD success\n",
    "RETURN success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29219ee",
   "metadata": {},
   "source": [
    "#### Uncover suspicious communities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983d7924",
   "metadata": {},
   "source": [
    "With communities identified, you can analyze their characteristics to spot potentially fraudulent patterns. You can examine the average risk scores, fraud rates (when present), and transaction patterns within each community. \n",
    "\n",
    "This analysis helps you prioritize which communities to investigate first, based on factors like high average risk scores, unusual transaction amounts, or suspicious patterns of shared features. The graph structure helps us see connections that might be missed in traditional tabular analysis.\n",
    "\n",
    "**Here you use the predictions of the GNN to rank communities by average risk score**, and since in this example all the data are annotated, you can also list the actual fraud rates for each community, as a way to verify the GNN predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2ee3b0",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%oc --store-to suspicious_communities\n",
    "\n",
    "MATCH (t:Transaction)\n",
    "WITH t.louvainCommunity as community_id,\n",
    "     count(t) as tx_count,\n",
    "     avg(t.pred) as avg_risk_score,\n",
    "     avg(t.isFraud) as avg_fraud\n",
    "WHERE tx_count > 10\n",
    "RETURN community_id, tx_count, avg_risk_score, avg_fraud\n",
    "ORDER BY avg_risk_score DESC LIMIT 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5798bc3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### Investigate Most Suspicious Community\n",
    "\n",
    "For communities flagged as high-risk, you can conduct a detailed examination\n",
    "of their transaction patterns. This includes analyzing the **types of features\n",
    "shared between transactions**, and the network of connections\n",
    "between high-risk transaction. \n",
    "\n",
    "The graph structure makes it easy to visualize and\n",
    "understand these relationships, revealing patterns that might indicate coordinated\n",
    "fraud attempts or compromised features being used across multiple transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb53592",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Exctract the id of the community with the highest average risk\n",
    "high_risk_community = suspicious_communities['results'][0]['community_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7981ec3e-db0f-4704-939a-f0f72f29c375",
   "metadata": {},
   "source": [
    "Here you can visualize the community ranked as the most suspicious and analyze the features that its transactions have by selecting the **Graph** tab from the output widget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8730d9a5",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%oc\n",
    "MATCH (n) WHERE n.louvainCommunity = ${high_risk_community}\n",
    "MATCH p=(n)-[]->()\n",
    "RETURN p\n",
    "LIMIT 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980e34eb-2765-4eda-8ce6-b90a22620393",
   "metadata": {},
   "source": [
    "You can use this kind of analysis to detect common elements in high-risk communities. For example, most of the transactions connecting to the same value for one of the Card node types or a particular Address."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feff403a",
   "metadata": {},
   "source": [
    "### Analyzing Feature Combinations in High-risk Transactions\n",
    "\n",
    "Moving beyond individual communities, you can analyze which combinations of features appear frequently in high-risk transactions. This helps identify \"suspicious patterns\" - combinations of attributes that might indicate fraudulent activity, and help you decide which types of features are actually useful to have in the graph.\n",
    "\n",
    "By leveraging the graph structure, you can easily find transactions sharing the same features, which would require complex joins in traditional SQL analysis. Instead here following the paths in the graph helps refine your understanding of fraud indicators.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f2be57",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%oc\n",
    "// This query identifies which types of features most commonly\n",
    "// connect high-risk transactions, helping to spot patterns\n",
    "// that might indicate fraudulent behavior\n",
    "\n",
    "// Start with a few high-risk transaction seeds\n",
    "MATCH (t1:Transaction)\n",
    "WHERE t1.pred > 0.6\n",
    "WITH t1 LIMIT 5\n",
    "\n",
    "// Transactions have 2-hop connections through feature rel,\n",
    "// named \"Transaction,identified_by,<feature_type>\".\n",
    "// Here we find feature nodes 'f' that connect our seed transactions\n",
    "// to other high-risk transactions\n",
    "MATCH path = (t1)-[r1]->(f)<-[r2]-(t2:Transaction)\n",
    "WHERE t1 <> t2\n",
    "  AND t2.pred > 0.6  // Both transactions are high risk\n",
    "  AND type(r1) CONTAINS 'identified_by'\n",
    "  AND type(r2) CONTAINS 'identified_by'\n",
    "//  AND split(type(r1), ',')[2] IN ['Card4', 'Card6']  // Optional: focus on specific features\n",
    "\n",
    "// Extract feature type from the edge type,\n",
    "// we split edge type names on the ',' character\n",
    "// and retain the <feature_type>  element\n",
    "WITH split(type(r1), ',')[2] as feature_type,\n",
    "     f,\n",
    "     t1,\n",
    "     t2\n",
    "LIMIT 50000 // Limits number of edges we review to help with result explosion\n",
    "// Analyze feature types and their connection patterns\n",
    "WITH feature_type,\n",
    "     count(DISTINCT f) as unique_feature_values,\n",
    "     count(DISTINCT t1) + count(DISTINCT t2) as transactions_connected,\n",
    "     avg(t1.pred + t2.pred)/2 as avg_risk_score,\n",
    "     avg(t1.isFraud + t2.isFraud)/2 as avg_actual_fraud\n",
    "\n",
    "RETURN\n",
    "    feature_type,\n",
    "    unique_feature_values,\n",
    "    transactions_connected,\n",
    "    round(1000.0 * avg_risk_score) / 1000.0 as avg_risk,\n",
    "    round(1000.0 * avg_actual_fraud) / 1000.0 as avg_fraud\n",
    "ORDER BY transactions_connected DESC\n",
    "LIMIT 20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c228012-e448-4f31-8afe-b068e091d818",
   "metadata": {},
   "source": [
    "During a fraud analysis you could use such a query to identify a number of risk indicators:\n",
    "\n",
    "1. **Identify Compromised Features:**\n",
    "   - If a `Card[4,6]` value connects many high-risk transactions with just a few (1-2) unique feature values, these specific card types might be compromised\n",
    "   - Few unique email domains connecting many transactions suggests specific email providers are frequently used in fraud\n",
    "\n",
    "2. **Pattern Recognition:**\n",
    "   - High `avg_fraud` rates across features confirm these connections are reliable fraud indicators\n",
    "   - Features with high `transactions_connected` but few `unique_features` (like Card6, Card4) might indicate reused fraudulent credentials\n",
    "\n",
    "3. **Investigation Prioritization:**\n",
    "   - Recipent (R) and Purchaser (P) EmailDomain with few unique values each connecting thousands of supsicious transactions might warrant investigation of specific suspicious domains\n",
    "\n",
    "4. **Risk Assessment:**\n",
    "   - The correlation between `avg_risk` (prediction) and `avg_fraud` (actual) validates the model's performance\n",
    "   - Features like `Address[1,2]` with few unique values might indicate specific locations being used for fraud\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e91cf7",
   "metadata": {},
   "source": [
    "### Analyze feature \"bridge\" values\n",
    "\n",
    "Finally, you can look for **specific** feature values that act as \"bridges\" connecting multiple high-risk transactions. These bridges might represent suspicious locations, compromised cards, suspicious email domains, or other attributes being reused across fraudulent transactions. \n",
    "\n",
    "This type of analysis drills down on the results from the previous query and is particularly powerful in graph form, as it naturally reveals fraud connection patterns. Understanding these bridges helps identify potential fraud enablers and improve detection mechanisms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859622ba",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%oc\n",
    "// This query identifies unique feature values that act as \"bridges\"\n",
    "// connecting multiple high-risk transactions\n",
    "// These features might be indicators of organized fraud\n",
    "\n",
    "// Start with high risk transactions and their unique feature values\n",
    "MATCH (f)<-[r]-(t:Transaction)\n",
    "WHERE t.pred > 0.6\n",
    "AND type(r) CONTAINS 'identified_by'\n",
    "WITH DISTINCT f, t\n",
    "\n",
    "// Analyze their connectivity patterns\n",
    "WITH f,\n",
    "     labels(f)[0] as feature_type,\n",
    "     count(DISTINCT t) as connected_tx,\n",
    "     sum(t.isFraud) as fraudulent_tx,\n",
    "     avg(t.pred) as avg_risk_score,\n",
    "     avg(t.isFraud) as avg_fraud_score\n",
    "WHERE connected_tx >= 100  // Unique feature values connecting at least 100 suspicious transactions\n",
    "\n",
    "RETURN\n",
    "    feature_type,\n",
    "    id(f) as feature_id,\n",
    "    connected_tx,\n",
    "    fraudulent_tx,\n",
    "    round(1000.0 * avg_risk_score) / 1000.0 as avg_risk,\n",
    "    round(1000.0 * avg_fraud_score) / 1000.0 as avg_fraud\n",
    "ORDER BY avg_risk DESC\n",
    "LIMIT 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7887b2f1-5074-47fd-95a9-71425418d5c9",
   "metadata": {},
   "source": [
    "Note that while the specific values for this dataset are anonymized, you can still draw some conclusions. \n",
    "In a real-world scenario you would have access to the original values for features like Address and the various card features, allowing you to focus your investigation on the particular values.\n",
    "\n",
    "1. **High-Volume Bridges:**\n",
    "   - Anonymized Card3 value `card3:150` connects thousands of risky transactions, that vast majority if which are fraudulent\n",
    "   - This single card feature value is a very strong fraud indicator\n",
    "\n",
    "2. **Payment Card Patterns:**\n",
    "   - Card1 feature `card1:15063` and `card2:nan` demonstrate very high risk and corresponding fraud rate.\n",
    "\n",
    "3. **Email Domain Analysis:**\n",
    "   - aol.com and anonymous.com email domains have very high predicted risk and should be flagged.\n",
    "\n",
    "Potential actions that you could take after combining the GNN prediction with your graph analytics:\n",
    " \n",
    "1. **Immediate Action Items:**\n",
    "   - Block or heavily scrutinize aol.com and anonymous.com email domains.\n",
    "   - Investigate all transactions with feature value card1:15063\n",
    "   - Block or heavily scrutinize transactions for `Address[1,2]` values listed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d7a409-f828-4b01-bf66-d77bf197ae5c",
   "metadata": {},
   "source": [
    "## Use graph embeddings to discover transactions similar to high-risk ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0a2434-70b8-4bb0-9101-3a890a1146f1",
   "metadata": {},
   "source": [
    "The node embeddings that the GNN model has created contain semantic information about the characteristics of each transaction. Using the predicted risk scores, you can isolate high-risk transactions, then expand your search to similar transactions to find characteristics that join them. For example, you can get the top-k most similar transactions to each high-risk transaction, and investigate the resulting graph.\n",
    "\n",
    "In the following query we start with 5 very high risk transactions, and collect the 3 most similar transactions to each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8b7d7d-a65f-4c8f-a8db-346ec58300a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%oc --store-to high_risk_neighbors\n",
    "MATCH (t:Transaction)\n",
    "WHERE t.pred >= 0.8\n",
    "WITH t LIMIT 5\n",
    "CALL neptune.algo.vectors.topKByNode(t, {topK: 4})\n",
    "YIELD node as similar_node, score\n",
    "WHERE id(t) <> id(similar_node) // Remove source node from query results\n",
    "RETURN id(t), id(similar_node), score as distance, similar_node.pred, similar_node.isFraud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3950dbf8-2894-47ee-bc6d-3b3b209b1662",
   "metadata": {},
   "source": [
    "You can then investigate the connections between these transactions by retrieving the paths connecting them. First extract the high-risk neighbor identifiers in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e22dc2c-36a4-457c-92c7-3b448a91b84a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "high_risk_neighbor_ids = [\n",
    "    entry['id(similar_node)'] for entry in high_risk_neighbors['results']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5486c166-983c-4e81-afb5-d65ca78185d9",
   "metadata": {},
   "source": [
    "Then submit a new OpenCypher query to extract the sub-graph that contains the suspicious similar transactions and their neighbors (features/identifiers). Run the following query and select the **Graph** tab for a graph view of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033674fb-db30-4ada-8e1d-dbec6771f72e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%oc\n",
    "MATCH (n) WHERE id(n) = ${high_risk_neighbor_ids}\n",
    "MATCH p=(n)-[]->()\n",
    "RETURN p\n",
    "LIMIT 1000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b5ae63-7b2c-4626-afc5-cfb6798a5d24",
   "metadata": {},
   "source": [
    "In this example, you can see that the transaction components are connected by bridge nodes of types Address2, Card6, and Card4 . You can use the values of these nodes, and find other transactions that share the same characteristics as another way to uncover potentially risky transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e0a94d-7959-42ea-9981-49e2de54b8b4",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates how to leverage both machine learning predictions \n",
    "and graph analytics in Amazon Neptune to enhance fraud detection capabilities. \n",
    "By combining GNN-generated risk scores with graph-based analysis, you've learned how to:\n",
    "\n",
    "1. **Validate and Enhance Risk Assessment**\n",
    "   - Used known fraud labels to validate GNN prediction accuracy across risk bands\n",
    "   - Identified cases where graph patterns reveal higher risk than individual predictions\n",
    "   - Demonstrated how network context improves fraud detection accuracy\n",
    "\n",
    "2. **Uncover Fraud Patterns**\n",
    "   - Identified specific feature values highly associated with fraud (>90% fraud rates)\n",
    "   - Discovered bridge features connecting thousands of suspicious transactions\n",
    "   - Found communities of related transactions showing coordinated fraud patterns\n",
    "\n",
    "3. **Enable Actionable Intelligence**\n",
    "   - Pinpointed specific features for immediate investigation (e.g., aol.com and anonymous.com email domains)\n",
    "   - Identified locations and card characteristics frequently involved in fraud\n",
    "   - Revealed patterns of feature sharing that indicate organized fraud\n",
    "\n",
    "The power of this approach lies in its unique combination of machine learning predictions, graph structure analysis, and known fraud labels. By integrating these three elements, you can create a comprehensive system that goes beyond simple risk scoring. \n",
    "\n",
    "While the GNN provides initial risk assessments, the graph structure reveals complex relationships and patterns that might be invisible when looking at transactions in isolation.\n",
    "\n",
    "This hybrid approach **significantly advances traditional fraud detection capabilities** by enabling the identification of entire fraud rings and coordinated activities, rather than just flagging individual suspicious transactions. \n",
    "\n",
    "For fraud analysts and investigators, this means being able to prioritize cases based on both risk scores and network context, while clearly visualizing how fraudulent activities are connected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69edeae5-96d5-43ca-b828-f4107e795021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
